const e=JSON.parse(`{"key":"v-459b0545","path":"/work-task/development/oss.html","title":"大文件上传","lang":"zh-CN","frontmatter":{"category":"工作任务","tag":["oss"],"description":"大文件上传 背景 文件上传是一个老生常谈的话题了，在文件相对比较小的情况下，可以直接把文件转化为字节流上传到服务器，但在文件比较大的情况下，用普通的方式进行上传，这可不是一个好的办法。 目前我们平台后管存在许多界面数据超过十几万条数据，常规的导出功能在面对如此大数据量的数据容易造成 OOM 等问题，因此需要一种新的上传方式来解决这个问题。 目前我们的导出都是通过后端使用 EasyExcel 生成文件上传到 OSS 并返回 OSS 地址的模式，想要解决大数据量的情况必须在生成文件和上传 OSS 的时候做出优化。 方案","head":[["meta",{"property":"og:url","content":"https://github.com/songbaicheng/songbaicheng.github.io/work-task/development/oss.html"}],["meta",{"property":"og:site_name","content":"Baicheng's Blog"}],["meta",{"property":"og:title","content":"大文件上传"}],["meta",{"property":"og:description","content":"大文件上传 背景 文件上传是一个老生常谈的话题了，在文件相对比较小的情况下，可以直接把文件转化为字节流上传到服务器，但在文件比较大的情况下，用普通的方式进行上传，这可不是一个好的办法。 目前我们平台后管存在许多界面数据超过十几万条数据，常规的导出功能在面对如此大数据量的数据容易造成 OOM 等问题，因此需要一种新的上传方式来解决这个问题。 目前我们的导出都是通过后端使用 EasyExcel 生成文件上传到 OSS 并返回 OSS 地址的模式，想要解决大数据量的情况必须在生成文件和上传 OSS 的时候做出优化。 方案"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-11T09:47:42.000Z"}],["meta",{"property":"article:author","content":"songbaicheng"}],["meta",{"property":"article:tag","content":"oss"}],["meta",{"property":"article:modified_time","content":"2025-08-11T09:47:42.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"大文件上传\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-11T09:47:42.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"songbaicheng\\",\\"url\\":\\"https://github.com/songbaicheng\\",\\"email\\":\\"songbaicheng16@163.com\\"}]}"]]},"headers":[{"level":2,"title":"背景","slug":"背景","link":"#背景","children":[]},{"level":2,"title":"方案","slug":"方案","link":"#方案","children":[{"level":3,"title":"秒传","slug":"秒传","link":"#秒传","children":[]},{"level":3,"title":"分片上传","slug":"分片上传","link":"#分片上传","children":[]},{"level":3,"title":"断点续传","slug":"断点续传","link":"#断点续传","children":[]}]},{"level":2,"title":"思路技巧","slug":"思路技巧","link":"#思路技巧","children":[]}],"git":{"createdTime":1754905662000,"updatedTime":1754905662000,"contributors":[{"name":"songbaicheng","email":"songbaicheng@sdpjw.com","commits":1}]},"readingTime":{"minutes":3.3,"words":990},"filePathRelative":"work-task/development/oss.md","localizedDate":"2025年8月11日","excerpt":"<h1> 大文件上传</h1>\\n<h2> 背景</h2>\\n<p>文件上传是一个老生常谈的话题了，在文件相对比较小的情况下，可以直接把文件转化为字节流上传到服务器，但在文件比较大的情况下，用普通的方式进行上传，这可不是一个好的办法。</p>\\n<p>目前我们平台后管存在许多界面数据超过十几万条数据，常规的导出功能在面对如此大数据量的数据容易造成 OOM 等问题，因此需要一种新的上传方式来解决这个问题。</p>\\n<p>目前我们的导出都是通过后端使用 EasyExcel 生成文件上传到 OSS 并返回 OSS 地址的模式，想要解决大数据量的情况必须在生成文件和上传 OSS 的时候做出优化。</p>\\n<h2> 方案</h2>","autoDesc":true}`);export{e as data};
