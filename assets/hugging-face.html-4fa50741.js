const e=JSON.parse(`{"key":"v-58701994","path":"/ai/llm/hugging-face.html","title":"Hugging Face","lang":"zh-CN","frontmatter":{"category":"AI","tag":["Hugging Face"],"description":"Hugging Face 学习 NLP 最优先级要学习的就是 Hugging Face，它提供了可以轻松地下载并且训练先进的预训练模型的 API 和工具。 我们要学习 Transformers 的模型、任务和设计理念，还有就是配置（configuration）、模型（model）、分词器（tokenizer）和流水线（pipeline）这几个最重要的类。","head":[["meta",{"property":"og:url","content":"https://github.com/songbaicheng/songbaicheng.github.io/ai/llm/hugging-face.html"}],["meta",{"property":"og:site_name","content":"Baicheng's Blog"}],["meta",{"property":"og:title","content":"Hugging Face"}],["meta",{"property":"og:description","content":"Hugging Face 学习 NLP 最优先级要学习的就是 Hugging Face，它提供了可以轻松地下载并且训练先进的预训练模型的 API 和工具。 我们要学习 Transformers 的模型、任务和设计理念，还有就是配置（configuration）、模型（model）、分词器（tokenizer）和流水线（pipeline）这几个最重要的类。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-08T05:59:02.000Z"}],["meta",{"property":"article:author","content":"songbaicheng"}],["meta",{"property":"article:tag","content":"Hugging Face"}],["meta",{"property":"article:modified_time","content":"2025-03-08T05:59:02.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Hugging Face\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-08T05:59:02.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"songbaicheng\\",\\"url\\":\\"https://github.com/songbaicheng\\",\\"email\\":\\"songbaicheng16@163.com\\"}]}"]]},"headers":[{"level":2,"title":"快速开始","slug":"快速开始","link":"#快速开始","children":[]},{"level":2,"title":"预处理数据","slug":"预处理数据","link":"#预处理数据","children":[{"level":3,"title":"自然语言处理","slug":"自然语言处理","link":"#自然语言处理","children":[]},{"level":3,"title":"音频","slug":"音频","link":"#音频","children":[]},{"level":3,"title":"计算机视觉","slug":"计算机视觉","link":"#计算机视觉","children":[]},{"level":3,"title":"多模态","slug":"多模态","link":"#多模态","children":[]}]},{"level":2,"title":"微调预训练模型","slug":"微调预训练模型","link":"#微调预训练模型","children":[]}],"git":{"createdTime":1739546562000,"updatedTime":1741413542000,"contributors":[{"name":"songbaicheng","email":"songbaicheng@sdpjw.com","commits":2}]},"readingTime":{"minutes":3.17,"words":951},"filePathRelative":"ai/llm/hugging-face.md","localizedDate":"2025年2月14日","excerpt":"<h1> Hugging Face</h1>\\n<p>学习 NLP 最优先级要学习的就是 Hugging Face，它提供了可以轻松地下载并且训练先进的预训练模型的 API 和工具。</p>\\n<p>我们要学习 Transformers 的模型、任务和设计理念，还有就是配置（configuration）、模型（model）、分词器（tokenizer）和流水线（pipeline）这几个最重要的类。</p>\\n","autoDesc":true}`);export{e as data};
