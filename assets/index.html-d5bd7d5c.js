import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{o as n,c as e,a as i}from"./app-1271f487.js";const r={},t=i('<h1 id="走进-ai" tabindex="-1"><a class="header-anchor" href="#走进-ai" aria-hidden="true">#</a> 走进 AI</h1><p>AI (artificial intelligence) 人工智能，AI领域非常广泛，包含了机器学习、强化学习、专家系统等多个子领域，但 <strong>计算机视觉（CV）</strong> 和 <strong>自然语言处理（NLP）</strong> 无疑是AI的两个主领域，因为它们直接涉及到人类与计算机的互动，并且在技术进步和商业化方面都取得了巨大成就。从名字就不难看出，CV 领域研究的是生物领域，而 NLP 领域研究则是偏向心理方向。</p><h2 id="大模型基础理解" tabindex="-1"><a class="header-anchor" href="#大模型基础理解" aria-hidden="true">#</a> 大模型基础理解</h2><p>机器学习是传统领域的的重点，它包括<strong>监督学习</strong>、<strong>无监督学习</strong>、<strong>强化学习</strong>与<strong>深度学习</strong>，监督学习是我们提供答案来让机器进行学习，无监督学习是让机器自己学习和理解事物的规律，强化学习则是让机器通过鼓励交互来学习和优化策略，深度学习则是通过神经网络来模拟人类大脑的运作。</p><p>在国内大模型发展的道路上，24年我们从卷体量卷基座卷算力到卷模型的应用，像agent中台，在2025年推测可能开始集中发展多模态。</p><p>大模型究竟如何使用呢，大模型的使用就是我们如何提需求的过程，大模型返回的结果可能会因为我们提示的几个字的不同而导致结果的不同，这就引出了另一个基础且重要的概念：<strong>提示工程</strong>（Prompt Engineering）。就像我们问体育老师数学问题一样，我们在使用一个模型之前都要进行训练让他术业有专攻，模型的训练要有以下几个过程：预训练、微调(SFT)、强化学习人类反馈（RLHF）、量化。</p><p>大模型到底大在哪里，大模型的核心在于其庞大的参数数量、强大的计算能力、大量的数据集预训练和适应性与灵活性强。大模型主要分类有两种分别是大语言模型（LLM）和多模态模型，大语言模型（LLM）专注于处理和理解自然语言，而多模态模型则能够同时理解和生成多种形式的数据，如文本、图像和视频等。大语言模型主要处理 NLP 问题，而多模态模型则可以处理更复杂、多样化的数据类型，像图片、音频、视频等。</p><h2 id="nlp-学习路线" tabindex="-1"><a class="header-anchor" href="#nlp-学习路线" aria-hidden="true">#</a> NLP 学习路线</h2><p>由于自己也是逐渐摸索，没有固定的学习路线，所以就按照自己了解的知识开始进行探索。目前在工作和生活中遇到场景大部分都是 NLP 领域相关的，也就是我们常见的 AIGC（Artificial Intelligence Generated Content），是指通过 人工智能（AI）技术生成的内容，它涵盖了由AI模型（如语言模型、图像生成模型、视频生成模型等）自动生成的各种形式的内容，包括但不限于文本、图像、音频、视频等，也就是我们常说的文生图、文生文、文生音、图生图等。</p><p>学习 NLP 要抓住一个核心两个工具，分别是 <strong>Hugging Face</strong>、<strong>PEFT</strong> 和 <strong>LangChain</strong> ，它们是当前在 自然语言处理（NLP） 和 生成式 AI 领域中非常流行和关键的框架或工具，首先我们先来介绍一下它们呢。</p><h2 id="hugging-face" tabindex="-1"><a class="header-anchor" href="#hugging-face" aria-hidden="true">#</a> Hugging Face</h2><p>Hugging Face 是一个开源社区和平台，提供了大量预训练的 transformer 模型，如 BERT、GPT、T5、BLOOM 等，并支持自然语言处理（NLP）的各种任务（如文本分类、命名实体识别、机器翻译、文本生成等）。</p><ul><li>提供了 transformers 库，简化了大规模预训练模型的使用，使得开发者可以快速加载、微调并部署各种模型。</li><li>拥有强大的 datasets 库，允许快速访问和加载各种 NLP 任务的数据集。</li><li>Hugging Face Hub 提供了一个模型共享平台，任何人都可以上传和下载模型，极大地推动了AI模型的开源共享。</li></ul><p>对于NLP的开发者和研究人员来说，Hugging Face 提供了几乎所有你需要的资源，是开发和应用生成式AI模型、预训练模型微调的核心平台。</p><h2 id="peft" tabindex="-1"><a class="header-anchor" href="#peft" aria-hidden="true">#</a> PEFT</h2><p>PEFT (Parameter-Efficient Fine-Tuning) 是一种高效的微调方法，旨在解决大规模预训练模型微调过程中的参数调整问题。与传统的微调方法不同，PEFT 通过修改模型中的少量参数来实现微调，从而大大减少了计算开销和存储需求。</p><ul><li>允许在有限的计算资源上进行大规模预训练模型的微调，特别适合资源有限的开发者或研究者。</li><li>常见的 PEFT 方法包括 LoRA（Low-Rank Adaptation）、Adapter、Prompt Tuning 等。</li><li>提供了更高效的训练和部署流程，避免了对整个模型进行微调的昂贵成本。</li></ul><p>对于需要在大规模预训练模型上进行高效微调的开发者来说，PEFT 提供了一种重要的思路和方法，尤其是在部署和扩展性方面。</p><h2 id="langchain" tabindex="-1"><a class="header-anchor" href="#langchain" aria-hidden="true">#</a> LangChain</h2><p>LangChain 是一个用于构建 语言模型驱动的应用程序 的框架，尤其适合 大语言模型（LLM）。它提供了用于集成外部知识库、数据库、API、文档、检索系统等的工具，以增强语言模型的功能，使其能够更好地处理现实世界中的复杂任务。</p><ul><li>支持与 外部数据源（如数据库、搜索引擎、API）进行交互，结合 文本生成 和 检索机制，实现更强大的推理能力。</li><li>可以方便地创建 多步骤 和 多任务 的工作流，构建更复杂的应用。</li><li>支持 语言模型链（Chain）、Agent 等构建方式，能够帮助开发者更灵活地构建对话式应用。</li></ul><p>LangChain 在处理 对话式AI 和 多任务协作 的场景中具有重要作用，尤其是在构建 智能助手、自动化问答系统、知识管理系统 时，非常有价值。</p><p>因此，学习这三个核心框架，可以让你在 自然语言处理 和 生成式AI 的领域内，快速掌握目前最热门和最有前景的技术，提升开发效率和能力。</p>',23),g=[t];function o(s,h){return n(),e("div",null,g)}const d=a(r,[["render",o],["__file","index.html.vue"]]);export{d as default};
