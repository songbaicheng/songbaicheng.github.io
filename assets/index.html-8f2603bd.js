import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{o as t,c as n,a as p}from"./app-eb1b47a8.js";const a={},o=p('<h1 id="llm" tabindex="-1"><a class="header-anchor" href="#llm" aria-hidden="true">#</a> LLM</h1><h2 id="基础" tabindex="-1"><a class="header-anchor" href="#基础" aria-hidden="true">#</a> 基础</h2><p>大语言模型（LLM）是通过预测下一个词的监督学习方式进行训练的。</p><p>具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入内容预测下一个词的概率分布。</p><p>通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。</p><p>基础语言模型（Base LLM）通过反复预测下一个词来训练的方式进行训练，没有明确的目标导向。</p><p>因此，如果给它一个开放式的prompt，它可能会通过自由联想生成戏剧化的内容。</p><p>相比之下，指令微调的语言模型（Instruction Tuned LLM）则进行了专门的训练，以便更好地理解问题并给出符合指令的回答。</p><p>那么，如何将基础语言模型转变为指令微调语言模型呢？</p><p>首先，在大规模文本数据集上进行无监督预训练，获得基础语言模型。 这一步需要使用数千亿词甚至更多的数据，在大型超级计算系统上可能需要数月时间。</p><p>之后，使用包含指令及对应回复示例的小数据集对基础模型进行有监督 fine-tune，这让模型逐步学会遵循指令生成输出，可以通过雇佣承包商构造适合的训练示例。</p><p>然后，您可以进一步调整语言模型，增加生成高评级输出的概率。这通常使用基于人类反馈的强化学习（RLHF）技术来实现。</p><h2 id="tokens" tabindex="-1"><a class="header-anchor" href="#tokens" aria-hidden="true">#</a> Tokens</h2><p>到目前为止对 LLM 的描述中，我们将其描述为一次预测一个单词，但实际上并不是重复预测下一个单词，而是重复预测下一个 token 。</p><p>对于一个句子，语言模型会先使用分词器将其拆分为一个个 token ，而不是原始的单词。</p><p>对于生僻词，可能会拆分为多个 token 。这样可以大幅降低字典规模，提高模型训练和推断的效率。</p><p>对于英文输入，一个 token 一般对应 4 个字符或者四分之三个单词；对于中文输入，一个 token 一般对应一个或半个词。</p><p>不同模型有不同的 token 限制，需要注意的是，这里的 token 限制是输入的 Prompt 和输出的 completion 的 token 数之和。</p>',18),r=[o];function i(c,d){return t(),n("div",null,r)}const l=e(a,[["render",i],["__file","index.html.vue"]]);export{l as default};
