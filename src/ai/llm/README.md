---
category: AI
tag:
  - LLM
---

# LLM

## 基础

大语言模型（LLM）是通过预测下一个词的监督学习方式进行训练的。

具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入内容预测下一个词的概率分布。

通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。

基础语言模型（Base LLM）通过反复预测下一个词来训练的方式进行训练，没有明确的目标导向。

因此，如果给它一个开放式的prompt，它可能会通过自由联想生成戏剧化的内容。

相比之下，指令微调的语言模型（Instruction Tuned LLM）则进行了专门的训练，以便更好地理解问题并给出符合指令的回答。

那么，如何将基础语言模型转变为指令微调语言模型呢？

首先，在大规模文本数据集上进行无监督预训练，获得基础语言模型。 这一步需要使用数千亿词甚至更多的数据，在大型超级计算系统上可能需要数月时间。

之后，使用包含指令及对应回复示例的小数据集对基础模型进行有监督 fine-tune，这让模型逐步学会遵循指令生成输出，可以通过雇佣承包商构造适合的训练示例。

然后，您可以进一步调整语言模型，增加生成高评级输出的概率。这通常使用基于人类反馈的强化学习（RLHF）技术来实现。

## Tokens

到目前为止对 LLM 的描述中，我们将其描述为一次预测一个单词，但实际上并不是重复预测下一个单词，而是重复预测下一个 token 。

对于一个句子，语言模型会先使用分词器将其拆分为一个个 token ，而不是原始的单词。

对于生僻词，可能会拆分为多个 token 。这样可以大幅降低字典规模，提高模型训练和推断的效率。

对于英文输入，一个 token 一般对应 4 个字符或者四分之三个单词；对于中文输入，一个 token 一般对应一个或半个词。

不同模型有不同的 token 限制，需要注意的是，这里的 token 限制是输入的 Prompt 和输出的 completion 的 token 数之和。

