---
category: AI
tag: 
  - 深度学习
---

# 深度学习入门

## 感知机

感知机是什么，就像电流流过导线，向前方输送电子一样，感知机的信号会形成流向前方输送信息，不过只有流（1）和不流（0）两种取值。

![基础感知机](/assets/images/ai/deep-learning/readme/基础感知机.png "基础感知机")

上面是一个接收两个输入信号的感知机的例子，其中 x1、x2 是输入信号，y 是输出信号，w1、w2
是权重，其中的圆形标志我们称为是节点或者是神经元，在输入信号被送往神经元的时候，会被乘以固定的权重然后相加（w1x1 +
w2x2），如果结果大于某个阈值（θ）则输出 1，否则输出 0，把上述内容用数学公式表示如下：

$$
y = \begin{cases}
1, \quad w_1 x_1 + w_2 x_2 \geq \theta \\
0, \quad w_1 x_1 + w_2 x_2 < \theta
\end{cases}
$$

## 与或非门

我们用感知机的思想通过代码来实现一下与或非门，然后一步一步升级变换一下，这样方便我们认识和理解感知机的一些其他概念。

首先我们从与门开始，逻辑与门需要遵循下面的规律：

| A | B | A AND B |
|---|---|---------|
| 0 | 0 | 0       |
| 0 | 1 | 0       |
| 1 | 0 | 0       |
| 1 | 1 | 1       |

根据上述规律，我们用 Python 代码实现一下与门：

```python
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1 * w1 + x2 * w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1
```

其中的参数选择完全由自己决定，只需要结果满足我们的与门定义即可，接下来我们用同样的方法实现或门和非门：

::: code-tabs#shell
@tab 或门

```python
def OR(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.3
    tmp = x1 * w1 + x2 * w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1
```

@tab 与非门

```python
def NAND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 1
    tmp = x1 * w1 + x2 * w2
    if tmp < theta:
        return 1
    elif tmp >= theta:
        return 0
```

:::

上面我们通过比较直接的方式实现了与或非门，接下来我们调整一下表达式的位置，将 θ 变成 -b 并移项到等号前，表达式就变成下面这样：

$$
y = \begin{cases}
1, \quad w_1 x_1 + w_2 x_2 + b \geq 0 \\
0, \quad w_1 x_1 + w_2 x_2 + b < 0
\end{cases}
$$

之前我们将 θ 称为阈值，可是它在新表达式中摇身一变，我们赋予他一个新的定义，叫做偏置（bias），它表示一个常数项，作用依旧是承担着神经元被激活的难易程度。我们使用权重和偏置来定义感知机，将上述三个门函数写成如下形式：

::: code-tabs#shell
@tab 与门

```python
def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w * x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

@tab 或门

```python
def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.3
    tmp = np.sum(w * x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

@tab 与非门

```python
def NAND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([-0.5, -0.5])
    b = 0.7
    tmp = np.sum(w * x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

:::

## 感知机的局限性

到这里大家都已经如何用感知机的思想实现与或非门了，下一步我们来考虑一下异或门的问题，异或门需要满足下面的规律：

| A | B | A XOR B |
|---|---|---------|
| 0 | 0 | 0       |
| 0 | 1 | 1       |
| 1 | 0 | 1       |
| 1 | 1 | 0       |

可能这样看上去我们并没有发现有什么异常，我们先拿之前的与或非门来举个例子，比如说或门，我们将我们代码中的变量放到表达式：

$$
y = \begin{cases}
1, \quad 0.5 x_1 + 0.5 x_2 - 0.3 \geq 0 \\
0, \quad 0.5 x_1 + 0.5 x_2 - 0.3 < 0
\end{cases}
$$

我们将 x1 和 x2 作为横坐标与纵坐标作图，会得到一条直线将坐标轴分为两个空间，左侧为0，右侧为1，如下图所示：

![or 感知机可视化](/assets/images/ai/deep-learning/readme/or.png "or 感知机可视化")

图中可以看到灰色区域是我们 or 感知机输出 0 的区域，其他两种与和与非门的图类似，那现在我们尝试先用图的方式来展示一下异或门：

[//]: # (不好画，等有空画一下)

从图中我们就可以看到，异或门的实现已经不能通过一条直线分开了，所以感知机的局限就在此处，只能表示由一条直线分割的空间。这里我们引入两个重要的概念。
- 线性空间：由直线分割而成的空间。
- 非线性空间：曲线分割而成的空间。

## 多层感知机
虽然感知机只能表示线性空间，可是感知机的绝妙之处在于它可以叠加态，这里我们继续借助异或门来研究感知机的叠加态概念，异或门的制作方式有很多，其中之一就是结合我们之前的与或非门进行组合

![通过组合实现 xor](/assets/images/ai/deep-learning/readme/xor.png "通过组合实现 xor")

根据图中的组合方式，用代码也是可以同样的组合方式：

```python
def XOR(x1, x2):
    s1 = NAND(x1, x2)
    s2 = OR(x1, x2)
    y = AND(s1, s2)
    return y
```

这里我们可以看出，与门、或门是单层感知机，而异或门是组合而成的 2 层感知机，这也就是感知机的叠加态，我们也能明白感知机可以通过叠加层进行非线性的表示。
