---
category: AI
tag:
  - 提示工程
  - 指令工程
---

# Prompt Engineering

随着 ChatGPT 等 LLM（大语言模型）的出现，自然语言处理的范式正在由 Pretrain-Finetune（预训练-微调）向提示工程演变。

对于具有较强自然语言理解、生成能力，能够实现多样化任务处理的 LLM 来说，一个合理的 Prompt 设计极大地决定了其能力的上限与下限。

Prompt Engineering，即是针对特定任务构造能充分发挥大模型能力的 Prompt 的技巧。 要充分、高效地使用 LLM，提示工程是必不可少的技能。

学习提示工程，你要明白为什么有的指令有效有的指令无效、怎么提升指令有效的概率、那些问题用提升工程更有效、那些用传统编程更快、能完成与业务系统的对接。

## Prompt 提示原则

好的 Prompt 不是一蹴而就的，要尝试，高质量 Prompt 的核心要点是：**具体、丰富、少歧异**，下面给出几个提示原则：

### 1. 编写清晰、具体的指令

用清晰、详尽的语言表达 Prompt，就像在给外星人讲解人类世界一样，你也可以使用角色定义，有论文表示，在提示词开始和结束的位置对模型影响是最大的，中间的内容反而影响最小。
其次可以加入例子，使用分隔符清晰地表示输入的不同部分，并加入结构化的输出。

### 2. 给模型时间去思考

在设计 Prompt 时，给予语言模型充足的推理时间非常重要。语言模型与人类一样，需要时间来思考并解决复杂问题。
我们可以指定完成任务所需的步骤，也可以指导模型在下结论之前找出一个自己的解法。

### 3. 局限性

开发大模型相关应用时请务必铭记：**模型偶尔会生成一些看似真实实则编造的知识**,

尽管模型经过大规模预训练，掌握了丰富知识，但它实际上并没有完全记住所见的信息，难以准确判断自己的知识边界，可能做出错误推断。

若让语言模型描述一个不存在的产品,它可能会自行构造出似是而非的细节。这被称为“幻觉”(Hallucination)，是语言模型的一大缺陷。

开发者可以通过Prompt设计减少幻觉发生的可能。例如，可以先让语言模型直接引用文本中的原句，然后再进行解答。这可以追踪信息来源，降低虚假内容的风险。

### 4. 英文原版 Prompt

在一些时候，英文原版 Prompt 往往比中文效果好，这是因为英文在歧义性上影响较小。值得注意的是，无论是那种语言的Prompt能够理解，除非该门语言十分小众。

## 防止 Prompt 漏洞

像著名的“奶奶漏洞”问题，通过变换用户角色等描述废弃掉之前的 Prompt 描述。解决大模型漏洞的方式和生活中的方式很像，解决方案有以下几种

### 注入分类器

在 Prompt 中加入分类器，让模型判断输入是否符合预期。在 Prompt 判断自己的结果是否符合之前要求进行拦截。

### 输入防御

在输入内容的前面都加上原则，比如说“作为……你不能回答与之无关的问题”。

## 具体应用
### 